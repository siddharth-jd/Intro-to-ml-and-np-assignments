{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsRI9D948KDb",
        "outputId": "a9d547b8-b59e-4116-fce0-202fd1dcb2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hclFpOU7CIV",
        "outputId": "f9c4a097-1e87-454a-df73-56b74f94065b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9479820627802691\n",
            "spam\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "w2v_model = api.load(\"glove-twitter-100\")  # ~25MB, 100-dim vectors\n",
        "\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "stopwords = set([\n",
        "    'i','me','my','myself','we','our','ours','ourselves','you','your','yours',\n",
        "    'yourself','yourselves','he','him','his','himself','she','her','hers',\n",
        "    'herself','it','its','itself','they','them','their','theirs','themselves',\n",
        "    'what','which','who','whom','this','that','these','those','am','is','are',\n",
        "    'was','were','be','been','being','have','has','had','having','do','does',\n",
        "    'did','doing','a','an','the','and','but','if','or','because','as','until',\n",
        "    'while','of','at','by','for','with','about','against','between','into',\n",
        "    'through','during','before','after','above','below','to','from','up','down',\n",
        "    'in','out','on','off','over','under','again','further','then','once','here',\n",
        "    'there','when','where','why','how','all','any','both','each','few','more',\n",
        "    'most','other','some','such','no','nor','not','only','own','same','so',\n",
        "    'than','too','very','can','will','just','don','should','now'\n",
        "])\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    words = ''.join(c if c.isalpha() else ' ' for c in text).split()\n",
        "    return [word for word in words if word not in stopwords]\n",
        "\n",
        "df['tokens'] = df['message'].apply(preprocess)\n",
        "\n",
        "def vectorize(tokens, model):\n",
        "    vectors = [model[word] for word in tokens if word in model]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "df['vector'] = df['tokens'].apply(lambda tokens: vectorize(tokens, w2v_model))\n",
        "\n",
        "X = np.vstack(df['vector'].values)\n",
        "y = (df['label'] == 'spam').astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n",
        "\n",
        "def predict_message_class(model, w2v_model, message):\n",
        "    tokens = preprocess(message)\n",
        "    vector = vectorize(tokens, w2v_model).reshape(1, -1)\n",
        "    pred = model.predict(vector)[0]\n",
        "    return 'spam' if pred == 1 else 'ham'\n",
        "\n",
        "print(predict_message_class(model, w2v_model, \"Free entry in 2 a weekly comp to win FA Cup final tickets. Text to enter now!\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q53WLfxT_25q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
